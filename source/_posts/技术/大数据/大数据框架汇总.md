---
title: 大数据框架汇总
categories:
  - 技术
tags:
  - 大数据
abbrlink: f2ce654
date: 2021-09-18 00:00:00
---

大数据平台相关框架汇总。
包括：Hadoop、Hbase、Pig、Hive、Spark、Strom、Flink、Presto、Atlas、SuperSet、Cassandra、ClickHouse等

<!-- more -->

## Hadoop
Hadoop是一个开源框架，允许使用简单的编程模型在跨计算机集群的分布式环境中存储和处理大数据。

Hadoop框架包括以下四个模块：
* Hadoop Common： 这些是其他Hadoop模块所需的Java库和实用程序。这些库提供文件系统和操作系统级抽象，并包含启动Hadoop所需的必要Java文件和脚本。
* Hadoop YARN： 这是作业调度和群集资源管理的框架。
* Hadoop分布式文件系统（HDFS）： 一种分布式文件系统，可提供对应用程序数据的高吞吐量访问。
* Hadoop MapReduce： 这是用于并行处理大型数据集的基于YARN的系统。

## Hbase
HBase是一个数据模型，基于 Apache Hadoop 和 BigTable 概念的宽列存储，旨在提供对大量结构化数据的快速随机访问。
HBase是一个面向列的建立在HDFS之上的非关系型数据库，利用了Hadoop文件系统（HDFS）提供的容错功能。
面向列的数据库是为巨大的表而设计的，对半结构化和结构化数据很有用，适用于在线分析处理（OLAP）。

## Flume
Apache Flume是一种分布式，高可靠和高可用的服务，可以有效采集、聚合和传输大量的日志数据。

Flume具有可调的可靠性机制和许多故障转移和恢复机制，主要用于将各种源的流数据传输到HDFS。

## Pig
由Yahoo开发，Apache Pig是对MapReduce的一种抽象。可以处理结构化，非结构化和半结构化的数据，分析结构化和半结构化的数据，并将结果存储在HDFS中。

Pig提供了一种称为 Pig Latin 的高级语言，不需要编译，执行时，每个操作符都在内部转换为MapReduce作业。

它提供了许多操作符来执行连接、排序、文件管理等操作，还提供了其他编程语言的自定义函数（UDF）功能，嵌入到Pig脚本中。

## Hive
由Facebook开发，Hive是一个数据仓库基础设施工具，用于处理Hadoop中的结构化数据。它位于Hadoop的顶部，用于汇总大数据，并使查询和分析变得轻松。

Hive提供用于查询的SQL类型语言，称为HiveQL或HQL，内部将HQL查询转换为执行MapReduce操作。

## Spark
Apache Spark是一款快速集群计算，专为快速计算而设计。它建立在Hadoop MapReduce之上，它扩展了MapReduce模型以有效地使用更多类型的计算，其中包括交互式查询和流处理。

Spark的主要特点是其内存集群计算 ，通过减少对磁盘的读/写操作，将中间处理数据存储在内存中，提高应用程序的处理速度。

包括以下四个组件：
* Apache Spark Core：Spark平台的基础通用执行引擎，其所有其他功能都是基于该平台执行的
* Spark SQL：提供了对结构化和半结构化数据的支持
* Spark Streaming：利用Spark Core的快速调度功能来执行流式分析
* MLlib：分布式机器学习框架
* GraphX：分布式图形处理框架

弹性分布式数据集（RDD）是Spark的基础数据结构，它是一个不可变的分布式对象集合。
Spark利用RDD的概念来实现更快更高效的MapReduce操作。

Apache Spark是用 Scala编程语言 编写的。为了用Spark支持Python，Apache Spark社区发布了一个工具PySpark。

## Storm
Apache Storm是一个分布式实时大数据处理系统。Storm设计用于以容错和水平可伸缩方法处理大量数据。虽然Storm是无状态的，但它通过Apache ZooKeeper管理分布式环境和集群状态。

Hadoop和Storm框架用于分析大数据，Storm执行除持久性以外的所有操作，而Hadoop擅长于一切，但缺乏实时计算。

## Flink
Apache Flink是一个同时面向数据流处理和批量数据处理的开源框架和分布式处理引擎，具有高吞吐、低延迟、高扩展、支持容错等特性，用于对无界和有界数据流进行有状态计算。

可以运行在包括 YARN、 Mesos、Kubernetes 在内的多种资源管理框架上。

### Flink 常见的几类应用
事件驱动型应用、数据分析应用、数据管道应用

#### 事件驱动型应用
事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据，并根据到来的事件触发计算、状态更新或其他外部动作。

事件驱动型应用是在计算存储分离的传统应用基础上进化而来。在传统架构中，应用需要读写远程事务型数据库。

典型的事件驱动型应用实例：反欺诈、异常检测、基于规则的报警、业务流程监控

#### 数据分析应用
数据分析任务需要从原始数据中提取有价值的信息和指标。传统的分析方式通常是利用批查询，或将事件记录下来并基于此有限数据集构建应用来完成。

Flink 为持续流式分析和批量分析都提供了良好的支持。内置了SQL接口，将批、流查询的语义统一起来。

#### 数据管道应用
提取-转换-加载（ETL）是一种在存储系统之间进行数据转换和迁移的常用方法。ETL 作业通常会周期性地触发，将数据从事务型数据库拷贝到分析型数据库或数据仓库。

Flink 为多种数据存储系统（如：Kafka、Kinesis、Elasticsearch、JDBC数据库系统等）内置了连接器

## mapReduce、pig/hive、spark/storm、flink
第一代计算引擎 mapReduce：
用于批处理，是计算引擎的先驱，开发效率低，开发时间成本太大

第二代计算引擎 pig/hive：
对hadoop进行了嵌套，其存储基于hdfs，计算基于mr，降低了mr的编写编写成本
pig有自己的脚本语言，可以处理非结构化、半结构化和结构化数据，比hive更加的灵活
hive属于类sql语法，仅支持处理结构化数据

第三代计算引擎 spark/storm：
解决实时处理的需求，低延迟高吞吐量。

第四代计算引擎 flink：
为流式计算而生属于每一条数据触发计算，在性能的消耗低于storm，吞吐量高于storm，延时低于storm，并且比storm更加易于编写

## Sqoop
它用于在HDFS和RDBMS之间导入和导出数据。

## Presto
Presto是Facebook开源的分布式SQL查询引擎，规模可以支持GB到PB级，主要应用于处理秒级的查询场景。内存中计算。优点是快，跨数据源查询

Hive针对查询吞吐量进行了优化，而Presto针对延迟进行了优化。
Presto受最大内存限制，如果超过最大内存，查询就会失败。
对于交互式查询可以接受，对于必须可靠运行的日报/周报，他是不合适的，Hive会更好。

## Atlas
Apache Atlas提供了开放元数据管理和治理能力，以建立其数据资产目录，对这些资产进行分类和治理。

开箱即用的元数据源集成：HBase、Hive、Sqoop、Storm、Kafka

## SuperSet
Apache Superset 是一个现代数据探索和可视化平台。
是一个现代轻量级的BI分析工具，功能强大且易于使用、轻量级且可扩展、与现代数据库集成、丰富的可视化和仪表板。

## Kafka
Apache Kafka 是一个开源分布式事件流平台，高吞吐量、弹性扩展、永久存储、高可用。

## Cassandra
由Facebook开发，Cassandra是一套开源分布式NoSQL数据库系统，基于 BigTable 和 DynamoDB 思想的宽列存储。

HBase vs Cassandra
https://appinventiv.com/blog/hbase-vs-cassandra/

当你需要分析大数据或执行聚合时请使用HBase，如果强调交互式数据和实时事务处理，可以使用 Cassandra。

## ClickHouse
ClickHouse是一个快速的开源 OLAP 数据库管理系统，它是面向列的，允许使用 SQL 查询实时生成分析报告。


## ETL
ETL是将业务系统的数据经过抽取（Extract）、清洗转换（Transform）之后加载（Load）到数据仓库的过程，目的是将企业中的分散、零乱、标准不统一的数据整合到一起，为企业的决策提供分析依据。

## ELK
ElasticSearch
Kibana
Logstash
Beats

