---
title: 凤凰架构-透明多层分流系统
categories:
  - 读书笔记
  - 技术
tags:
  - 凤凰架构
abbrlink: fd2df2c4
date: 2021-08-09 00:00:00
---

周志明《凤凰架构：构建可靠的大型分布式系统》
https://icyfenix.cn/

包括：域名解析，客户端缓存，传输链路，传输压缩，内容分发，负载均衡，服务端缓存。

<!-- more -->
透明多级分流系统的设计原则：

* 第一个原则是尽可能减少单点部件，如果某些单点是无可避免的，则应尽最大限度减少到达单点部件的流量。
* 第二个原则是奥卡姆剃刀原则，它更为关键。”如无必要，勿增实体“

## 域名解析(DNS)
以 www.icyfenix.com.cn 为例，介绍DNS把域名解析成IP地址的过程：

1. 客户端先检查本地的 DNS 缓存，查看是否存在并且是存活着的该域名的地址记录。
2. 客户端将地址发送给本机操作系统中配置的本地 DNS（Local DNS）
3. 本地 DNS 收到查询请求后，会按照顺序依次查找地址记录，“ www.icyfenix.com.cn 的权威服务器”→“ icyfenix.com.cn 的权威服务器”→“ com.cn 的权威服务器”→“cn 的权威服务器”→“根域名服务器“。
4. 现在假设本地 DNS 是全新的，上面不存在任何域名的权威服务器记录，当 DNS 查询请求一直查到根域名服务器之后，会得到“cn 的权威服务器”的地址记录，然后通过“cn 的权威服务器”，得到“com.cn 的权威服务器”的地址记录，以此类推，最后找到能够解释 www.icyfenix.com.cn 的权威服务器地址。
5. 通过“www.icyfenix.com.cn 的权威服务器”，查询 www.icyfenix.com.cn 的地址记录。

DNS 的分级查询都有可能受到中间人攻击的威胁，产生被劫持的风险。

HTTPDNS（也称为 DNS over HTTPS，DoH）：它把原本的 DNS 解析服务开放为一个基于 HTTPS 协议的查询服务，替代基于 UDP 传输协议的 DNS 域名解析，通过程序代替操作系统直接从权威 DNS，或者可靠 Local DNS 获取解析数据，从而绕过传统 Local DNS。

> “切勿浪费较多东西，去做‘用较少的东西，同样可以做好的事情’。”
> 手上有个新锤子，看啥都是对口的钉子。

## 客户端缓存
分为强制缓存和协商缓存，这两套机制是并行工作。当强制缓存超过时效或者被禁用，协商缓存也仍然可以正常工作。

### 强制缓存
根据资源的修改时间进行检查

#### Expires
Expires 是 HTTP/1.0 协议中开始提供的 Header，后面跟随了一个截止时间参数

> HTTP/1.1 200 OK
> Expires: Wed, 8 Apr 2020 07:28:00 GMT

问题：
* 受限于客户端的本地时间
* 无法处理涉及到用户身份的私有资源
* 无法描述“不缓存”的语义

#### Cache-Control
Cache-Control 是 HTTP/1.1 协议中定义的强制缓存 Header，与 Expires 同时存在，且语义存在冲突时，IETF 规定必须以 Cache-Control 为准。

> HTTP/1.1 200 OK
> Cache-Control: max-age=600

* max-age：相对于请求时间多少秒内，缓存是有效的
* s-maxage：“共享缓存”的有效时间，即允许被 CDN、代理等持有的缓存有效时间
* public：意味着资源可以被代理、CDN 等缓存
* private：就意味着只能由用户的客户端进行私有缓存
* no-cache：表明该资源不应该被缓存，哪怕是同一个会话中对同一个 URL 地址的请求
* no-store：不强制会话中是否重复获取相同的 URL 资源，禁止浏览器、CDN 等以任何形式保存该资源
* no-transform：禁止资源以任何形式被修改，包括Content-Encoding、Content-Range、Content-Type
* min-fresh：仅用于客户端的请求 Header，用于建议服务器能返回一个不少于该时间的缓存资源
* only-if-cached：表示客户端只会接受代理缓存，而不会接受源服务器的响应。如果代理缓存无效，就直接返回 503/Service Unavailable 错误
* must-revalidate：表示在资源过期后，一定要从服务器中进行获取
* proxy-revalidate：用于提示代理、CDN 等设备资源过期后的缓存行为，语义与 must-revalidate 完全一致

### 协商缓存
根据资源唯一标识是否发生变化来进行检查

#### 根据资源的修改时间进行检查
Last-Modified：服务器的响应 Header，用来告诉客户端这个资源的最后修改时间
If-Modified-Since：客户端再次请求时，会通过 If-Modified-Since，把之前收到的资源最后修改时间发送回服务端

服务端发现资源在该时间后没有被修改过，就只要返回一个 304/Not Modified 的响应即可
```
HTTP/1.1 304 Not Modified
Cache-Control: public, max-age=600
Last-Modified: Wed, 8 Apr 2020 15:31:30 GMT
```

#### 根据资源唯一标识是否发生变化来进行检查
Etag：是服务器的响应 Header，用于告诉客户端这个资源的唯一标识
If-None-Match：当客户端需要再次请求时，就会通过 If-None-Match，把之前收到的资源唯一标识发送回服务端

## 传输链路

### 前端网页的优化技巧
* 最少请求数量：TCP连接开销很大，解决手段有雪碧图，文件合并，媒体内联等
* 扩大并发请求数：现代浏览器一般支持6个并发请求，解决手段域名分片
* 启用压缩传输：减少网络传输内容的大小
* 避免页面重定向：页面发生了重定向，就会延迟整个文档的传输
* 按重要性调节资源优先级：对客户端展示影响大的资源，放在 HTML 的头部，以便优先下载
* ...

因为 HTTP 协议还在持续发展，这些优化技巧可能会成为反模式。
HTTP/3以前是以 TCP 为传输层的应用层协，TCP 协议本身是面向长时间、大数据传输来设计的。
而每个页面包含的资源（HTML、CSS、JS、图片等）的特征是，数量多，资源小。
以至于 HTTP/1.x 时代，大量短而小的 TCP 连接导致了网络性能的瓶颈。

### Keep-Alive 机制
（HTTP/1.0 中不是默认开启的，HTTP/1.1 中变为默认）
原理是让客户端对同一个域名长期持有一个或多个不会用完即断的 TCP 连接。客户端维护一个 FIFO 队列，每次取完数据之后的一段时间内，不自动断开连接，下一个资源时可以直接复用，避免创建 TCP 连接的成本。

副作用：队首阻塞，首个资源是一个复杂的请求，导致后面的请求必须阻塞等待。

### HTTP/2 的多路复用技术

在 HTTP/1.x 中，HTTP 请求就是传输过程中最小粒度的信息单位，如果将多个请求切碎，再混杂在一块传输，客户端难以分辨重组出有效信息。
而在 HTTP/2 中，帧（Frame）才是最小粒度的信息单位。它可以用来描述各种数据，比如请求的 Headers、Body，或者是用来做控制标识，如打开流、关闭流。
流（Stream）是一个逻辑上的数据通道概念，每个帧都附带有一个流 ID，以标识这个帧属于哪个流。

多路复用的支持，HTTP/2 就可以对每个域名只维持一个 TCP 连接，开发者也不用去考虑并发请求数限制，客户端就不需要再刻意压缩 HTTP 请求。

在 HTTP 传输中，Headers 占传输成本的比重是相当地大，HTTP/2 中专门考虑如何进行 Header 压缩的问题，同一个连接上产生的请求和响应越多，头部压缩效果也就越好。所以 HTTP/2 是单域名单连接的机制，合并资源和域名分片反而对性能提升不利。

与 HTTP/1.x 相反，HTTP/2 本身反而变得更适合传输小资源。

### 传输压缩
当客户端可以接受压缩版本的资源时（请求的 Header 中包含 Accept-Encoding: gzip），就返回压缩后的版本（响应的 Header 中包含 Content-Encoding: gzip），否则就返回未压缩的原版。

#### 静态预压缩
在网络时代的早期，服务器的处理能力还很薄弱，为了启用压缩，会把静态资源预先压缩为.gz 文件的形式给存放起来。

#### 即时压缩
现代的 Web 服务器处理能力有了大幅提升，整个压缩过程全部在内存的数据流中完成，不必等资源压缩完成再返回响应，这样可以显著提高首字节时间，改善 Web 性能体验。

在 HTTP/1.0 时，资源结束判断的机制，只有根据 Content-Length 判断。
但即时压缩时，服务器再也没有办法给出 Content-Length 这个响应 Header 了。
所以，如果是 HTTP/1.0 的话，持久连接和即时压缩只能二选其一。
在 HTTP/1.0 中这两者都支持，却默认都是不启用。

#### 分块编码
HTTP/1.1中，增加了另一种资源结束判断的机制，“分块传输编码”（Chunked Transfer Encoding）。

工作原理：在响应 Header 中加入“Transfer-Encoding: chunked”之后，就代表这个响应报文将采用分块编码。此时，报文中的 Body 需要改为用一系列“分块”来传输。每个分块包含十六进制的长度值和对应长度的数据内容，长度值独占一行，数据从下一行开始。最后以一个长度值为 0 的分块，来表示资源结束。

### 快速 UDP 网络连接
想从根本上改进 HTTP，就必须直接替换掉 HTTP over TCP 的根基，即 TCP 传输协议。2018 年末，IETF 正式批准了 HTTP over QUIC 使用 HTTP/3 的版本号，它会以 UDP 协议作为基础。

## 内容分发网络(CDN)

CDN 其实就是做“内容分销”工作的。

内容分发网络的工作过程，主要涉及到路由解析、内容分发、负载均衡和它所能支持的应用内容四个方面。

仅从网络传输的角度来看，一个互联网系统的速度快慢，主要取决于以下四点因素：
1. 网站服务器接入网络运营商的链路所能提供的出口带宽。
2. 用户客户端接入网络运营商的链路所能提供的入口带宽。
3. 从网站到用户之间，经过的不同运营商之间互联节点的带宽。
4. 从网站到用户之间的物理链路传输时延。

### 路由解析

![CDN 路由解析](https://gitee.com/lights8080/lights8080-oss/raw/master/2021/08/kCQhKS.png)


### 内容分发
无论是对用户还是服务器，内容分发网络都可以是完全透明的，CDN需要解决两个问题：“如何获取源站资源”和“如何管理（更新）资源”。

#### 第一种：主动分发（Push）
主动分发就是由源站主动发起，将内容从源站或者其他资源库推送到用户边缘的各个 CDN 缓存节点上。

通常需要源站、CDN 服务双方提供的程序 API 接口层面的配合。

#### 第二种：被动回源（Pull）
由用户访问所触发的全自动、双向透明的资源缓存过程。当某个资源首次被用户请求的时候，CDN 缓存节点如果发现自己没有该资源，就会实时从源站中获取。

可以做到完全的双向透明，不需要源站在程序上做任何的配合，使用起来非常方便。

#### 如何管理（更新）资源
对于Cache-Control的 s-maxage，是否遵循，完全取决于 CDN 本身的实现策略。

CDN 缓存的管理没有通用的准则，最常见的管理（更新）资源的做法是超时被动失效与手工主动失效相结合。

### CDN 应用
* 加速静态资源
* 安全防御，DDoS攻击
* 协议升级，https，IPv6
* 状态缓存
* 修改资源，给源站不支持跨域的资源提供跨域能力
* 访问控制，QoS控制，referer防盗链
* 注入功能，Google Analytics等

## 负载均衡(Load Balancing)
“负载均衡器”（Load Balancer）：承担了调度后方的多台机器，以统一的接口对外提供服务的技术组件。

从形式上来说都可以分为两种：四层负载均衡和七层负载均衡。四层负载均衡的优势是性能高，七层负载均衡的优势是功能强。


|     | <div style="width:135px">**层**</div> | <div style="width:75px">**数据单元**</div> | **功能**                                                                                                                                         |
| --- | ------------------------------------- | ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------ |
| 7   | 应用层 <br/>Application Layer         | 数据<br/>Data                              | 提供为应用软件提供服务的接口，用于与其他应用软件之间的通信。典型协议：HTTP、HTTPS、FTP、Telnet、SSH、SMTP、POP3 等                               |
| 6   | 表达层<br/>Presentation Layer         | 数据 <br/>Data                             | 把数据转换为能与接收者的系统格式兼容并适合传输的格式。                                                                                           |
| 5   | 会话层 <br/>Session Layer             | 数据 <br/>Data                             | 负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接。                                                                                 |
| 4   | 传输层 <br/>Transport Layer           | 数据段<br/>Segments                        | 把传输表头加至数据以形成数据包。传输表头包含了所使用的协议等发送信息。典型协议：TCP、UDP、RDP、SCTP、FCP 等                                      |
| 3   | 网络层 <br/>Network Layer             | 数据包<br/>Packets                         | 决定数据的传输路径选择和转发，将网络表头附加至数据段后以形成报文（即数据包）。典型协议：IPv4/IPv6、IGMP、ICMP、EGP、RIP 等                       |
| 2   | 数据链路层 <br/>Data Link Layer       | 数据帧<br/>Frame                           | 负责点对点的网络寻址、错误侦测和纠错。当表头和表尾被附加至数据包后，就形成数据帧（Frame）。典型协议：WiFi（802.11）、Ethernet（802.3）、PPP 等。 |
| 1   | 物理层<br/>Physical Layer             | 比特流<br/>Bit                             | 在局域网上传送数据帧，它负责管理电脑通信设备和网络媒体之间的互通。包括了针脚、电压、线缆规范、集线器、中继器、网卡、主机接口卡等。               |

#### 四层负载均衡
四层负载均衡的工作模式都属于“转发”，即直接将承载着 TCP 报文的底层数据格式（IP 数据包或以太网帧），转发到真实服务器上，此时客户端到响应请求的真实服务器维持着同一条 TCP 通道。

**数据链路层负载均衡**
数据链路层传输的内容是数据帧（Frame），只需要注意到“MAC 目标地址”和“MAC 源地址”两项即可。

工作原理：修改请求的数据帧中的 MAC 目标地址，让用户原本是发送给负载均衡器的请求的数据帧，被二层交换机根据新的 MAC 目标地址，转发到服务器集群中，对应的服务器的网卡上，这样真实服务器就获得了一个原本目标并不是发送给它的数据帧。

数据链路层负载均衡的工作模式是，只有请求会经过负载均衡器，而服务的响应不需要从负载均衡器原路返回，整个请求、转发、响应的链路形成了一个“三角关系”，又叫“三角传输模式”，“单臂模式”，“直接路由”。

二层负载均衡器工作原理决定了，它们必须位于同一个子网当中，无法跨 VLAN。这个优势（效率高）和劣势（不能跨子网）就共同决定了，数据链路层负载均衡最适合用来做数据中心的第一级均衡设备，用来连接其他的下级负载均衡器。

**网络层负载均衡**
网络层传输的单位是分组数据包（Packets），只要知道在 IP 分组数据包的 Headers 带有源和目标的 IP 地址即可。

第一种：保持原来的数据包不变，新创建一个数据包。(IP隧道)
优点：
* 并没有修改原有数据包中的任何信息，仍然具备三角传输特性
* IP 隧道工作在网络层，所以可以跨越 VLAN

缺点：
* 真实服务器收到数据包后，必须在接收入口处，设计拆包机制。(几乎所有Linux系统都支持IP隧道协议)
* 必须保证所有的真实服务器与均衡器有着相同的虚拟 IP 地址

第二种：改变目标数据包，直接把数据包 Headers 中的目标地址改掉(NAT 模式)
NAT模式：充当了家里、公司、学校的上网路由器的作用。

优点：
* 没有经过 IP 隧道的额外包装，无需再拆包了
* 彻底的透明，真实服务器连网关都不需要配置，均衡器在转发时不仅修改目标 IP 地址，连源 IP 地址也一起改了

缺点：
* 不具备三角传输特性，必须回到负载均衡，改回自己的IP，再发给客户端。流量压力比较大时，带来较大的性能损失
* 真实服务器处理请求时就无法拿到客户端的 IP 地址


#### 应用层负载均衡
工作在四层之后的负载均衡模式就无法再进行转发了，只能进行代理。此时正式服务器、负载均衡器、客户端三者之间，是由两条独立的 TCP 通道来维持通讯的。

![转发与代理](https://gitee.com/lights8080/lights8080-oss/raw/master/2021/08/uHa47g.jpg)

分类：
* 正向代理就是我们通常简称的代理，意思就是在客户端设置的、代表客户端与服务器通讯的代理服务。它是客户端可知，而对服务器是透明的。
* 反向代理是指设置在服务器这一侧，代表真实服务器来与客户端通讯的代理服务。此时它对客户端来说是透明的。
* 透明代理是指对双方都透明的，配置在网络中间设备上的代理服务。比如，架设在路由器上的透明翻墙代理。

七层负载均衡器，不能去做下载站、视频站这种流量应用，起码不能作为第一级均衡器。
缺点：网络性能比不过四层负载均衡器，多一轮TCP握手，还有 NAT 转发模式一样的带宽问题
优点：可以感知应用层通讯的具体内容，往往能够做出更明智的决策

应用：
* 缓存方面的工作，比如静态资源缓存、协议升级、安全防护、访问控制等
* 更智能化的路由，比如Session 路由、亲和性集群、URL路由、根据用户路由等
* 某些安全攻击可以由七层负载均衡器来抵御，比如DDoS 手段是 SYN Flood 攻击
* 链路治理措施，比如服务降级、熔断、异常注入等
* ...

#### 均衡策略与实现

均衡策略与实现
* 轮循均衡
* 权重轮循均衡
* 随机均衡
* 权重随机均衡
* 一致性哈希均衡
* 响应速度均衡
* 最少连接数均衡

负载均衡器的实现有“软件均衡器”和“硬件均衡器”两类。

软件均衡器又分为直接建设在操作系统内核的均衡器和应用程序形式的均衡器两种。前者的代表是 LVS（Linux Virtual Server），后者的代表有 Nginx、HAProxy、KeepAlived，等等；前者的性能会更好，因为它不需要在内核空间和应用空间中来回复制数据包；而后者的优势是选择广泛，使用方便，功能不受限于内核版本。

硬件均衡器，往往会直接采用应用专用集成电路来实现。因为它有专用处理芯片的支持，可以避免操作系统层面的损耗，从而能够达到最高的性能。这类的代表就是著名的 F5 和 A10 公司的负载均衡产品。

## 缓存(Cache)
服务端缓存是一种通用的技术组件，它主要用于减少多个客户端相同的资源请求，缓解或降低服务器的负载压力。

引入缓存的理由，1）为了缓解 CPU 压力而做缓存，2）为了缓解 I/O 压力而做缓存。
如果你可以通过增强 CPU、I/O 本身的性能（比如扩展服务器的数量）来满足需要的话，那升级硬件往往是更好的解决方案。

吞吐量（每秒操作数，Operations per Second，ops/s）：它反映了对缓存进行并发读、写操作的效率，即缓存本身的工作效率高低。
缓存的吞吐量只在并发场景中才有统计的意义，所以，并发读写的场景中，“尽可能避免数据竞争”是最关键的。
针对伴随读写操作而来的状态维护，有两种处理思路。一种是以 Guava Cache 为代表的同步处理机制，另一种是以 Caffeine 为代表的异步日志提交机制。

缓存策略：
* FIFO（First In First Out）：优先淘汰最早进入被缓存的数据
* LRU（Least Recent Used）：优先淘汰最久未被使用访问过的数据
* LFU（Least Frequently Used）：优先淘汰最不经常使用的数据
* TinyLFU（Tiny Least Frequently Used）：TinyLFU 是 LFU 的改进版本，通过用少量的样本数据来估计全体数据的特征。用相对小得多的记录频率和空间，来近似地找出缓存中的低价值数据。

扩展知识：
> 1. ConcurrentHashMap（JDK8）中读操作完全没有线程安全措施，无论是CAS还是Synchronized都没有做。写操作是通过CAS来做节点位置判断，通过Synchronized来修改值。单个值级别的锁定意味着只有不同线程、修改同一个值才会有锁竞争。不同线程修改不同的值不会竞争相同的锁，或者相同线程修改同一个值锁是可重入的，简而言之“有锁”并不一定是指“有竞争”。
> 2. 软件开发两大难题，一个是缓存失效，该失效时未失效，不该失效时失效，另一个是命名。
> 3. 环形缓冲(Ring Buffer)：它是一种拥有读、写两个指针的数据复用结构。

### 分布式缓存
缓存可以分为“进程内缓存”和“分布式缓存”两大类。

进程内缓存：只为节点本身提供服务，无网络访问操作，速度快但缓存的数据不能在各个服务节点中共享。
分布式缓存：与进程内缓存相反，处理与网络有关的操作是影响吞吐量的主要因素。分为复制式缓存与集中式缓存。

复制式缓存，可以看作是“能够支持分布式的进程内缓存”，工作原理与 Session 复制类似，代表是JBossCache。缺点是复制性能会随着节点的增加呈现平方级下降，基本上已经很难再见到使用这种缓存形式的大型信息系统了。
集中式缓存，是目前分布式缓存的主流形式，代表是Redis。缺点是缓存的读、写都需要网络访问，不可能再达到进程内缓存那样的高性能。好处是不会随着集群节点数量的增加而产生额外的负担.

分布式缓存集群是否能保证数据一致性，也可以将它分为 AP 和 CP 两种类型，通常不太会使用缓存来处理追求强一致性的数据。
Redis 集群就是典型的 AP 式，它具有高性能、高可用等特点，但它却并不保证强一致性。而能够保证强一致性的 ZooKeeper、Doozerd、Etcd 等分布式协调框架，通常不会把它们当作“缓存框架”来使用。倒是常跟 Redis 和其他分布式缓存搭配工作，用来实现其中的通知、协调、队列、分布式锁等功能。

分布式缓存与进程内缓存各有所长，它们是互补的，而不是竞争的关系。所以，完全可以同时互相搭配，来构成透明多级缓存（Transparent Multilevel Cache，TMC）。

多级缓存的意思是，使用进程内缓存做一级缓存，分布式缓存做二级缓存。但代码侵入性较大，不便于管理，数据更新更是麻烦，很容易出现一二级缓存里的数据不一致。
如何“透明”地解决这些问题，多级缓存才具有实用的价值。
一种常见的设计原则，就是变更以分布式缓存中的数据为准，访问以进程内缓存的数据优先。大致做法是当数据发生变动时，在集群内发送推送通知（引入ZooKeeper 或 Etcd 来处理），让各个节点的一级缓存自动失效掉相应数据。

### 缓存风险

#### 缓存穿透
查询的数据在数据库中根本不存在的话，请求的流量每次都不会命中，每次都会触及到末端的数据库。这种查询不存在数据的现象，就被称为缓存穿透。

解决办法：
1）对于业务逻辑本身就不能避免的缓存穿透，约定一定时间内，返回空的Key依然进行缓存。
2）对于恶意攻击导致的缓存穿透，设置布隆过滤器，用最小的代价，判断某个元素是否存在。

#### 缓存击穿
缓存中的某些热点数据忽然因为某种原因失效了，都到达真实数据源中去，导致其压力剧增。这种现象，就被称为缓存击穿。

解决办法：
1）加锁同步，以请求该数据的 Key 值为锁，其他线程采取阻塞或重试策略。
2）热点数据由代码来手动管理

#### 缓存雪崩
由于大批不同的数据在短时间内一起失效，导致了这些数据的请求都击穿了缓存，到达数据源。这种现象，就被称为缓存雪崩。

解决办法：
1）提升缓存系统可用性，建设分布式缓存的集群。
2）分散了它们的过期时间
3）将缓存的生存期从固定时间改为一个时间段内的随机时间

#### 缓存污染
缓存中的数据与真实数据源中的数据不一致的现象。

为了尽可能地提高使用缓存时的一致性，人们已经总结了不少更新缓存时可以遵循的设计模式，比如 Cache Aside、Read/Write Through、Write Behind Caching，等等。

##### Cache Aside：
* 读数据时，先读缓存，缓存没有的话，再读数据源，然后将数据放入缓存，再响应请求。
* 写数据时，先写数据源，然后失效（而不是更新）掉缓存。

Cache Aside 模式依然也不能保证在一致性上绝对不出问题，采用 Cache Aside 模式典型的出错场景，就是如果某个数据是从未被缓存过的，请求会直接流到真实数据源中，如果数据源中的写操作发生在查询请求之后，结果回填到缓存之前，也会出现缓存中回填的内容与数据库的实际数据不一致的情况。
但是，出现这种情况的概率实际上是很低的，Cache Aside 模式仍然是以低成本更新缓存，并且获得相对可靠结果的解决方案。

##### Read/Write Through
* Read Through，读数据时，先读缓存，缓存没有的话，由缓存组件负责读数据源将数据放入缓存，再响应请求。
* Write Through，写数据时，先写入缓存，由缓存组件负责同步更新到数据源中。

##### Write Behind Caching
Write back是相较于Write Through而言的一种异步回写策略，由缓存组件负责异步更新到数据源中。适用于读少写多的场景。

