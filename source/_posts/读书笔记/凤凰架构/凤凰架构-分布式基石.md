---
title: 凤凰架构-分布式基石
categories:
  - 读书笔记
  - 技术
tags:
  - 凤凰架构
abbrlink: 846371ce
date: 2021-10-26 00:00:00
---

周志明《凤凰架构：构建可靠的大型分布式系统》
https://icyfenix.cn/

包括：分布式共识、服务发现、网关、负载均衡、服务容错、限流、零信任网络安全、可观测性
<!-- more -->

## 1. 分布式共识
### 可靠与可用、共识与一致
状态转移（State Transfer）：以同步为代表的数据复制方法。这类方法属于比较符合人类思维的可靠性保障手段，但通常要以牺牲可用性为代价。
操作转移（Operation Transfer）：在分布式系统里主流的数据复制方法是，通过某种操作，把源状态转换为目标状态。

让系统各节点不受局部的网络分区、机器崩溃、执行性能或者其他因素影响，能最终表现出整体一致的过程，就是各个节点的协商共识（Consensus）。
共识（Consensus）与一致性（Consistency）是有区别的：一致性指的是数据不同副本之间的差异，而共识是指达成一致性的方法与过程。

### Paxos 算法
Paxos 算法：一种基于消息传递的协商共识算法，几乎就是“共识”这两字的代名词了。
Paxos 算法将分布式系统中的节点分为提案节点、决策节点和记录节点三类，包括“准备（Prepare）”和“批准（Accept）”两个阶段。

### Raft 算法
Multi Paxos 对 Basic Paxos 的核心改进是，增加了“选主”的过程。
以上这种把共识问题分解为“Leader Election”、“Entity Replication”和“Safety”三个问题来思考、解决的解题思路，就是Raft 算法。

http://thesecretlivesofdata.com/raft/

### Gossip 协议
Paxos、Raft、ZAB 等分布式算法经常会被称作是“强一致性”的分布式共识协议。
强一致性的意思是“尽管系统内部节点可以存在不一致的状态，但从系统外部看来，不一致的情况并不会被观察到，所以整体上看系统是强一致性的”。
Gossip 协议，是一种很有代表性的“最终一致性”的分布式共识协议。

## 2. 服务发现
如何确定目标方法的确切位置，便是与编译链接有着等同意义的问题，解决该问题的过程，就被叫做“服务发现”（Service Discovery）。服务发现要解决注册、维护和发现三大功能问题。

因为远程服务的多样性，导致了“服务发现”也会有两种不同的理解：
一种是以 UDDI 为代表的“百科全书式”的服务发现。
另一种是类似于 DNS 这样的“门牌号码式”的服务发现。(主流地位)

### 服务发现需要有效权衡一致性与可用性的矛盾
对系统的可用性和可靠性的取舍不同，对服务发现框架的具体实现也有着决定性的影响。

第一类：在分布式 K/V 存储框架上自己实现的服务发现：
Etcd 采用的是我们学习过的 Raft 算法，ZooKeeper 采用的是 ZAB 算法。

第二类：以基础设施（主要是指 DNS 服务器）来实现服务发现
Kubernetes 1.3 之后，SkyDNS 不再是默认的 DNS 服务器：AP。

第三类：专门用于服务发现的框架和工具
Consul：CP，Eureka：AP，Nacos：同时支持CP和AP(二选一)。

## 3. 网关
网关 = 路由器（基础职能） + 过滤器（可选职能）
在“路由”这个基础职能里，服务网关主要考虑的是能够支持路由的“网络层次与协议”和“性能与可用性”两方面的因素。

BFF（Backends for Frontends）：网关不必为所有的前端提供无差别的服务，而是应该针对不同的前端，聚合不同的服务，提供不同的接口和网络访问协议支持。

### 网络层次与协议
负载均衡器与服务网关的区别在于，前者是为了根据均衡算法对流量进行平均地路由，后者是为了根据流量中的某种特征进行正确地路由。

### 性能与可用性
我们可以把网络 I/O 模型总结为两类、五种模型。两类是指同步 I/O 与异步 I/O；五种是指在同步 I/O 中又划分出了阻塞 I/O、非阻塞 I/O、多路复用 I/O 和信号驱动 I/O 四种细分模型。

多路复用 I/O 还可以细分 select、epoll、kqueue 等不同实现。
信号驱动 I/O 与异步 I/O 的区别是“从缓冲区获取数据”这个步骤的处理，

在网关的可用性方面，我们应该考虑到以下几点：网关应尽可能轻量、应该尽可能选择较成熟的产品实现、在网关之前部署负载均衡器或者等价路由器（ECMP）。

## 4. 负载均衡
分为集中式的负载均衡（Nginx）、客户端负载均衡器（Netflix Ribbon）、代理客户端负载均衡器（Service Mesh）

### Region
Region 是地域的意思，比如华北、东北、华东、华南，这些都是地域范围。不同的地域之间是没有内网连接的。

### Zone
Zone 是区域的意思，它是可用区域（Availability Zones）的简称。区域的意思是在地理上位于同一地域内，但电力和网络是互相独立的物理区域，比如在华东的上海、杭州、苏州的不同机房，就是同一个地域的几个可用区域。同一个地域的区域之间具有内网连接，流量不占用公网带宽，因此区域是微服务集群内，流量能够触及的最大范围。

异地容灾和异地双活的差别：容灾是非实时的同步，而双活是实时或者准实时的，跨地域或者跨区域做容灾都可以，但只能一般只能跨区域做双活，当然你也可以将它们结合起来同时使用，即“两地三中心”模式。

## 5. 服务容错
容错策略，指的是“面对故障，我们该做些什么”；而容错设计模式，指的是“要实现某种容错策略，我们该如何去做”。

### 容错策略
7 种常见的容错策略，包括故障转移、快速失败、安全失败、沉默失败、故障恢复、并行调用和广播调用。

![容错策略](https://static001.geekbang.org/resource/image/da/7c/da6e01c336443bd125ff94bb4be3997c.jpg)

### 容错设计模式
微服务中常见的断路器模式、舱壁隔离模式和超时重试模式等，以及流量控制模式，比如滑动时间窗模式、漏桶模式、令牌桶模式，等等。

#### 断路器模式
断路器一般可以设置为 CLOSED、OPEN 和 HALF OPEN 三种状态。

服务熔断和服务降级之间的联系与差别：
* 断路器做的事情是自动进行服务熔断，属于一种快速失败的容错策略的实现方法。
* 服务降级是上游服务必须能够主动处理调用失败的后果，也不一定是在出现错误后才被动执行的，我们在很多场景中谈论的降级更可能是指，需要主动迫使服务进入降级逻辑的情况。

#### 舱壁隔离模式
服务隔离，就是避免某一个远程服务的局部失败影响到全局，而设置的一种止损方案。

#### 重试模式
我们判断是否应该且是否能够对一个服务进行重试时，要看是否同时满足下面 4 个条件。
1. 仅在主路逻辑的关键服务上进行同步的重试
2. 仅对由瞬时故障导致的失败进行重试
3. 仅对具备幂等性的服务进行重试
4. 重试必须有明确的终止条件，常用的终止条件有超时终止和次数终止两种

## 6. 限流
任何一个系统的运算、存储、网络资源都不是无限的，当系统资源不足以支撑外部超过预期的突发流量时，就应该要有取舍，建立面对超额流量自我保护的机制，而这个机制就是微服务中常说的“限流”。

### 流量统计指标
每秒事务数（Transactions per Second，TPS）：是衡量信息系统吞吐量的最终标准，逻辑上具备原子性的业务操作。(最希望的限流指标)
每秒请求数（Hits per Second，HPS）：每秒从客户端发向服务端的请求数。(首选的限流指标，相对容易观察统计)
每秒查询数（Queries per Second，QPS）：一台服务器能够响应的查询次数。

限流设计模式包括流量计数器、滑动时间窗、漏桶和令牌桶。

## 7. 零信任网络安全

### 基于边界的安全模型
边界安全着重检查的是经过网络区域边界的流量，而对可信任区域（内网）内部机器之间的流量，会给予直接信任、或者至少是较为宽松的处理策略，这样就减小了安全设施对整个应用系统复杂度的影响，以及网络传输性能的额外损耗。如VPN、DMZ、防火墙、内网、外网，这些概念，都是基于边界的安全模型。

### 零信任安全模型
零信任安全的中心思想是不应当以某种固有特征来自动信任任何流量，除非明确得到了能代表请求来源（不一定是人，更可能是另一台服务）的身份凭证，否则一律不会有默认的信任关系。

![传统的基于边界的网络安全模型，与云原生时代下基于零信任网络的安全模型之间的差异](https://static001.geekbang.org/resource/image/36/f9/363a4d538e4d4a3a15d87258dyy59ef9.jpg)

### 建立信任
* 单向 TLS 认证：只需要服务端提供证书，客户端通过服务端证书验证服务器的身份，但服务器并不验证客户端的身份。单向 TLS 用于公开的服务，即任何客户端都被允许连接到服务进行访问，它保护的重点是客户端免遭冒牌服务器的欺骗。
* 双向 TLS 认证：客户端、服务端双方都要提供证书，双方各自通过对方提供的证书来验证对方的身份。双向 TLS 用于私密的服务，即服务只允许特定身份的客户端访问，它除了保护客户端不连接到冒牌服务器外，也保护服务端不遭到非法用户的越权访问。


认证分为两种类型，一种是以机器作为认证对象，即访问服务的流量来源是另外一个服务，这被叫做服务认证（Peer Authentication，直译过来是“节点认证”）；另一种是以人类作为认证对象，即访问服务的流量来自于最终用户，这被叫做请求认证（Request Authentication）。

#### 服务认证
* Istio：无需改动任何代码，启用 mTLS 认证，且提供了宽容模式，宽容模式为普通微服务向服务网格迁移提供了良好的灵活性。
* spring cloud：在应用层面去实现，使用OAuth 2.0协议进行认证。客户端在调用服务时，会先使用该密钥向认证服务器申请到 JWT 令牌，然后通过令牌证明自己的身份，最后访问服务。

#### 请求认证
* Istio：能够自动根据配置中的JWKS验证验证请求中附带的 JWT 是否合法，整个认证过程不需要应用程序参与。JWKS 就是一组 JWK 的集合。支持 JWKS 的系统，能通过 JWT 令牌 Header 中的 KID（Key ID）自动匹配出应该使用哪个 JWK 来验证签名。
* spring cloud：Spring Security 已经做好了认证所需的绝大部分工作，真正要开发者去编写的代码就是令牌的具体实现。

#### 授权
经过认证之后，合法的调用者就有了可信任的身份，此时就不再需要区分调用者到底是机器（服务）还是人类（最终用户）了，只需要根据其身份角色来进行权限访问控制就行，即我们常说的 RBAC。分别针对来自“服务”和“用户”的流量来控制权限和访问范围。
* Istio：便捷性、安全性、无侵入、统一管理
* spring cloud：一种是使用ExpressionUrlAuthorizationConfigurer，通过编码进行集中配置，第二种是使用@RolesAllowed、@PreAuthorize，以注解的形式分散写到每个服务甚至是每个方法中。

## 8. 可观测性
可观测性原本的含义是“可以由系统的外部输出推断其内部状态的程度”。不过实际上，计算机科学中关于可观测性的研究内容已经有了很多年的实践积累。通常，人们会把可观测性分解为三个更具体的方向进行研究，分别是：日志收集、链路追踪和聚合度量。

### 日志（Logging）
日志主要是用来记录系统运行期间发生过的离散事件。
在日志领域，日志收集和分析大多被统一到了 Elastic Stack（ELK）技术栈上。
ELK 在一定程度上也可以代替度量和追踪系统，实现它们的部分职能，对于大型系统，建议还是让专业的工具去做专业的事情。

#### 日志的记录
好的日志要能够毫无遗漏地记录信息、格式统一、内容恰当，而“恰当”的真正含义是指日志中不该出现的内容不要有，而该有的不要少。
* “不应该有”的日志内容：避免打印敏感信息、避免引用慢操作、避免打印追踪诊断信息、避免误导他人。
* “不应该少”的日志内容：处理请求时的 TraceID、系统运行过程中的关键事件、启动时输出配置信息

#### 分布式系统处理日志
分布式系统处理一个请求要跨越多个服务节点，因此当每个节点输出日志到文件后，就必须要把日志文件统一收集起来，集中存储、索引，而这正是日志收集器需要做的工作。此外，日志收集器还要尽力保证日志数据的连续性。

#### 日志的查询、统计、聚合等操作
由于日志是非结构化数据，因此我们需要进行加工，把日志行中的非结构化数据转换为结构化数据，以便针对不同的数据项来建立索引，进行条件查询、统计、聚合等操作。

* 一种解决方案是通过 Elasticsearch 本身的处理能力做实时的聚合统计，应对于即席查询。
* 另一种解决方案是在收集日志后自动生成某些常用的、固定的聚合指标，这种聚合就会在 Logstash 中通过聚合插件来完成，更多是用于应对固定查询。

### 追踪（Tracing）
从广义上讲，一个完整的分布式追踪系统，应该由数据收集、数据存储和数据展示三个相对独立的子系统构成；而从狭义上讲，则就只是特指链路追踪数据的收集部分。比如Spring Cloud Sleuth就属于狭义的追踪系统，通常会搭配 Zipkin 作为数据展示，搭配 Elasticsearch 作为数据存储来组合使用。

所有业界有名的追踪系统，无论是国外 Twitter 的Zipkin、Naver 的Pinpoint，还是国内阿里的鹰眼、大众点评的CAT、个人开源的SkyWalking（后来进入 Apache 基金会孵化毕业），都受到了 Dapper 论文（Google 在 2010 年发表）的直接影响。

Dapper 提出了“追踪”（Trace）与“跨度”（Span）两个概念，每一次 Trace 都是由若干个有顺序、有层级关系的 Span 所组成一颗“追踪树”（Trace Tree）

数据收集的三种主流实现方式：基于日志的追踪、基于服务的追踪、基于边车代理的追踪。

#### 基于日志的追踪
日志追踪对网络消息完全没有侵入性，对应用程序只有很少量的侵入性，对性能的影响也非常低。
缺点是直接依赖于日志归集过程，由于日志归集不及时或者精度丢失，导致日志出现延迟或缺失记录，进而产生追踪失真的情况。
日志追踪的代表产品是 Spring Cloud Sleuth。

#### 基于服务的追踪
是目前最为常见的追踪实现方式，实现思路是通过某些手段给目标应用注入追踪探针。
基于服务的追踪会比基于日志的追踪消耗更多的资源，也具有更强的侵入性，而换来的收益就是追踪的精确性与稳定性都有所保证，不必再依靠日志归集来传输追踪数据。
Zipkin、SkyWalking、Pinpoint 等主流追踪系统广泛采用。

#### 基于边车代理的追踪
基于边车代理的追踪是服务网格的专属方案，也是最理想的分布式追踪模型，它对应用完全透明，无论是日志还是服务本身，都不会有任何变化。
市场占有率最高的边车代理Envoy就提供了相对完善的追踪功能。

#### 追踪规范化
当初 Google 发表的 Dapper 只是论文，而不是有约束力的规范标准，它只提供了思路，并没有规定细节。
为了推进追踪领域的产品标准化，2016 年 11 月，CNCF 技术委员会接受了 OpenTracing 作为基金会的第三个项目。
Google 在这个时候出来表示反对，并提出了与 OpenTracing 目标类似的 OpenCensus 规范，随后又得到了巨头 Microsoft 的支持和参与。
2019 年，OpenTracing 和 OpenCensus 又忽然宣布握手言和，它们共同发布了可观测性的终极解决方案OpenTelemetry，并宣布会各自冻结 OpenTracing 和 OpenCensus 的发展。

### 度量（Metrics）
度量（Metrics）的目的是揭示系统的总体运行状态，更重要目的是监控（Monitoring）和预警（Alert）。
度量就是用经过聚合统计后的高维度信息，以最简单直观的形式来总结复杂的过程，为监控、预警提供决策支持。
在总体上，度量可以分为客户端的指标收集、服务端的存储查询以及终端的监控预警三个相对独立的过程，每个过程在系统中一般也会设置对应的组件来实现。

#### 指标收集
如何定义指标？数据类型（Metrics Types）：
* 计数度量器（Counter）：对有相同量纲、可加减数值的合计量
* 瞬态度量器（Gauge）：表示某个指标在某个时点的数值
* 吞吐率度量器（Meter）：用于统计单位时间的吞吐量，即单位时间内某个事件的发生次数
* 直方图度量器（Histogram）：二维统计图，它的两个坐标分别是统计样本和该样本对应的某个属性的度量，以长条图的形式记录具体数值
* 采样点分位图度量器（Quantile Summary）：通过比较各分位数的分布情况的工具，主要用来验证实际值与理论值的差距，评估理论值与实际值之间的拟合度

如何将这些指标告诉服务端？
通常有两种解决方案：拉取式采集（Pull-Based Metrics Collection）和推送式采集（Push-Based Metrics Collection）

Prometheus 在基于 Pull 架构的同时，还能够有限度地兼容 Push 式采集。

#### 存储查询
时序数据库：时序数据库是用于存储跟随时间而变化的数据，并且以时间（时间点或者时间区间）来建立索引的数据库。它具有不变性、唯一性、有序性。时序数据库同时具有数据结构简单、数据量大的特点。

Prometheus 服务端自己就内置了一个强大的时序数据库实现，在DB-Engines中近几年它的排名就在不断提升。

#### 监控预警
广义上的度量系统由面向目标系统进行指标采集的客户端，负责调度、存储和提供查询能力的服务端，以及面向最终用户的终端组成。
狭义上的度量系统就只包括客户端和服务端，不包含终端。

大多是 Prometheus 配合 Grafana 来进行展示的，这是 Prometheus 官方推荐的组合方案。

良好的可视化能力对于提升度量系统的产品力也非常重要，长期趋势分析、对照分析、故障分析等分析工作，既需要度量指标的持续收集、统计，往往还需要对数据进行可视化，这样才能让人更容易地从数据中挖掘规律，毕竟数据最终还是要为人类服务的。

传统监控和可观测性之间的关键区别在于：可观测性是系统或服务内在的固有属性，而不是在系统之外对系统所做出的额外增强，后者是传统监控的处理思路。

Prometheus 提供了专门用于预警的 Alert Manager。

